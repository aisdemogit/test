{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce64102-cd25-4566-b996-3c45c9971360",
   "metadata": {},
   "source": [
    "# Evaluating the Original OpenLlama and the Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b39f1-563e-4d8d-a423-0391ae8c5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c40db8-f499-4d11-b5aa-d7397e219ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '3B' #'7B' # Pick your poison\n",
    "\n",
    "if model == '7B':\n",
    "    model_name = (\"togethercomputer/RedPajama-INCITE-Base-7B-v0.1\",\"togethercomputer/RedPajama-INCITE-Base-7B-v0.1\")\n",
    "    run_name = 'redpj7B-lora-int8-alpaca'\n",
    "    dataset = 'johnrobinsn/alpaca-cleaned'\n",
    "    peft_name = 'redpj7B-lora-int8-alpaca'\n",
    "    output_dir = 'redpj7B-lora-int8-alpaca-results'\n",
    "else: #3B\n",
    "    model_name = (\"togethercomputer/RedPajama-INCITE-Base-3B-v1\",\"togethercomputer/RedPajama-INCITE-Base-3B-v1\")\n",
    "    run_name = 'redpj3B-lora-int8-alpaca'\n",
    "    dataset = 'johnrobinsn/alpaca-cleaned'\n",
    "    peft_name = 'redpj3B-lora-int8-alpaca'\n",
    "    output_dir = 'redpj3B-lora-int8-alpaca-results'\n",
    "\n",
    "model_name[1],dataset,peft_name,run_name\n",
    "\n",
    "report_to = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dac5dc-0ba9-42a1-9b4b-b08b1e90eb3c",
   "metadata": {},
   "source": [
    "## load base LLM model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2d080-aa40-497f-b92e-83bc43af3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name[0],\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name[1])\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.add_special_tokens({'eos_token':'<eos>'})\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d634da-0a06-419d-b763-afe1828c0996",
   "metadata": {},
   "source": [
    "## Formatting Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9ad72-f9f8-4247-9d1b-6ceb9f71873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afe0df-a857-4ce4-9be4-adc4bd734143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction,input=None,maxTokens=256):\n",
    "    prompt = generate_prompt({'instruction':instruction,'input':input})\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=maxTokens, \n",
    "                             do_sample=True, top_p=0.9,pad_token_id=tokenizer.eos_token_id,\n",
    "                             forced_eos_token_id=tokenizer.eos_token_id)\n",
    "    outputs = outputs[0].tolist()\n",
    "    # Stop decoding when hitting the EOS token\n",
    "    if tokenizer.eos_token_id in outputs:\n",
    "        eos_index = outputs.index(tokenizer.eos_token_id)\n",
    "        decoded = tokenizer.decode(outputs[:eos_index])\n",
    "        # Don't show the prompt template\n",
    "        sentinel = \"### Response:\"\n",
    "        sentinelLoc = decoded.find(sentinel)\n",
    "        if sentinelLoc >= 0:\n",
    "            print(decoded[sentinelLoc+len(sentinel):])\n",
    "        else:\n",
    "            print('Warning: Expected prompt template to be emitted.  Ignoring output.')\n",
    "    else:\n",
    "        print('Warning: no <eos> detected ignoring output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad957b1-2671-472f-9f4a-976cbc410d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f224b678-e00c-46ff-ae09-3b21c7477445",
   "metadata": {},
   "source": [
    "# Generating using the Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f891ac-323a-44b0-af9e-75f47148918d",
   "metadata": {},
   "source": [
    "## Write a short story in third person narration about a protagonist who has to make an important career decision.\n",
    "The protagonistâ€™s character is presented from the point of view of the protagonist. The first paragraph should describe a decision the protagonist made. In the second paragraph, the reader should learn more about the protagonist and why she made this decision. In the last paragraph, the reader should learn more about what the protagonist decided.\n",
    "\n",
    "### Examples:\n",
    "Write about a character from a novel who makes an important decision.\n",
    "Write about a character from a film that makes an important decision.\n",
    "Write about a character from a television show that makes an important decision.\n",
    "\n",
    "## Writing Prompt 13: Write a Short Story\n",
    "\n",
    "### Instructions:\n",
    "In the following prompt, write a short story in third person narration. The story can take place in the past or in the present. Write a story that contains:\n",
    "\n",
    "- An unreliable narrator\n",
    "- A dramatic situation\n",
    "- A situation that takes place during a specific time\n",
    "\n",
    "### Response:\n",
    "Write a short story in third person narration about a character who finds an important item. The character finds the item during a specific time. The story contains the following characteristics:\n",
    "\n",
    "- An unreliable narrator\n",
    "- A dramatic situation\n",
    "- A situation that takes place during a specific time\n",
    "\n",
    "### Examples:\n",
    "Write a short story about a character who finds an important item during a specific time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a629cfb-749a-4768-87fd-eca7399bcf3d",
   "metadata": {},
   "source": [
    "## Before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a85929-5cff-42a8-b62b-8216778b11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "instruction = 'Who was the first man to walk on the moon and tell me where he was born.'\n",
    "generate(instruction ,maxTokens=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2929848-6c9f-41fe-8b3c-74fcffef6cd6",
   "metadata": {},
   "source": [
    "## Load the LORA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f62eda-b267-4270-bec6-5e48175338f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = f'johnrobinsn/{peft_name}' # By default use my pretrained adapter weights\n",
    "#peft_model_id = peft_name # Uncomment to use locally saved adapter weights if you trained above\n",
    "\n",
    "# Load the LoRA model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})\n",
    "model.eval()\n",
    "\n",
    "print(\"Peft model adapter loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0c1a2-ba78-4dc4-a255-1f467b13863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "instruction = 'Who was the first man to walk on the moon and tell me where he was born.'\n",
    "generate(instruction ,maxTokens=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ce573-c3a1-4669-b5d8-f2c30c86ee95",
   "metadata": {},
   "source": [
    "## A few more prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205392c3-efc8-4fe7-9269-c6c230b8c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "generate('Identify the odd one out','Twitter, Instagram, Telegram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2946b-5ce0-4048-85d5-910f1d6bd5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265cfd5-122f-4a50-9530-ff9869bd7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "generate('Write a poem about about a cat',maxTokens=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
